import json
from langchain_openai import ChatOpenAI
from langchain_experimental.agents.agent_toolkits import create_pandas_dataframe_agent

PROMPT_TEMPLATE = """
ä½ æ˜¯ä¸€ä½æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œä¸“æ³¨ä¸åˆ†æå­¦ç”Ÿçš„æˆç»©ï¼Œä½ çš„å›åº”å†…å®¹å–å†³äºç”¨æˆ·çš„è¯·æ±‚å†…å®¹ã€‚

1. å¯¹äºæ–‡å­—å›ç­”çš„é—®é¢˜ï¼ŒæŒ‰ç…§è¿™æ ·çš„æ ¼å¼å›ç­”ï¼š
   {"answer": "<ä½ çš„ç­”æ¡ˆå†™åœ¨è¿™é‡Œ>"}
ä¾‹å¦‚ï¼š
   {"answer": "è®¢å•é‡æœ€é«˜çš„äº§å“IDæ˜¯'MNWC3-067'"}

2. å¦‚æœç”¨æˆ·éœ€è¦ä¸€ä¸ªè¡¨æ ¼ï¼ŒæŒ‰ç…§è¿™æ ·çš„æ ¼å¼å›ç­”ï¼š
   {"table": {"columns": ["column1", "column2", ...], "data": [[value1, value2, ...], [value1, value2, ...], ...]}}

3. å¦‚æœç”¨æˆ·çš„è¯·æ±‚é€‚åˆè¿”å›æ¡å½¢å›¾ï¼ŒæŒ‰ç…§è¿™æ ·çš„æ ¼å¼å›ç­”ï¼š
   {"bar": {"columns": ["A", "B", "C", ...], "data": [34, 21, 91, ...]}}

4. å¦‚æœç”¨æˆ·çš„è¯·æ±‚é€‚åˆè¿”å›æŠ˜çº¿å›¾ï¼ŒæŒ‰ç…§è¿™æ ·çš„æ ¼å¼å›ç­”ï¼š
   {"line": {"columns": ["A", "B", "C", ...], "data": [34, 21, 91, ...]}}

5. å¦‚æœç”¨æˆ·çš„è¯·æ±‚é€‚åˆè¿”å›æ•£ç‚¹å›¾ï¼ŒæŒ‰ç…§è¿™æ ·çš„æ ¼å¼å›ç­”ï¼š
   {"scatter": {"columns": ["A", "B", "C", ...], "data": [34, 21, 91, ...]}}
æ³¨æ„ï¼šæˆ‘ä»¬åªæ”¯æŒä¸‰ç§ç±»å‹çš„å›¾è¡¨ï¼š"bar", "line" å’Œ "scatter"ã€‚

6. "å¦‚æœç”¨æˆ·æé—®â€œç¬¬næ¬¡å’Œç¬¬n-1æ¬¡è€ƒè¯•é—´å„ç­è¿›æ­¥æœ€å¤§çš„äººæ˜¯è°â€ï¼ŒæŒ‰ç…§è¿™æ ·çš„é€»è¾‘ä¸€æ­¥ä¸€æ­¥æ¥å›ç­”ï¼š
    {"åœ¨ç”¨æˆ·ä¸Šä¼ çš„è¡¨æ ¼ä¸­ï¼Œæœ‰ä¸€æ æ˜¯â€œè€ƒè¯•ï¼ˆå¦‚ï¼šç¬¬1æ¬¡è€ƒè¯•ã€ç¬¬2æ¬¡è€ƒè¯•ã€‚ã€‚ã€‚ã€‚ç¬¬n-1æ¬¡è€ƒè¯•ã€ç¬¬næ¬¡è€ƒè¯•ï¼‰â€ï¼Œ
    ä½ éœ€è¦ç”¨çš„åˆ—æ˜¯â€œå§“åâ€ã€â€œè€ƒè¯•â€ã€â€œç­çº§â€å’Œâ€œæ’åâ€ï¼Œä½ éœ€è¦å…ˆå€Ÿç”¨å·¥å…·è®¡ç®—æ¯ä¸ªäººè¢«ç”¨æˆ·æŒ‡å®šçš„ä¸¤æ¬¡è€ƒè¯•å¯¹åº”æ’åçš„å·®å€¼ï¼Œå·®å€¼è¶Šå¤§ä»£è¡¨è¿›æ­¥è¶Šå¤§ï¼ˆä½†å·®å€¼å¿…é¡»è¦æ˜¯æ­£æ•°æ‰æœ‰æ„ä¹‰ï¼Œå¿½ç•¥æ‰è´Ÿå€¼ï¼‰ï¼Œ
    ç„¶åæ ¹æ®ç­çº§è¿›è¡Œåˆ†ç±»ï¼Œæ¯ä¸ªç­ä¸­æ’åå·®å€¼æœ€å¤§çš„ä¸ºè¿›æ­¥æœ€å¤§çš„å­¦ç”Ÿï¼Œæœ€åæ‰¾å‡ºè¿”å›æ¯ä¸ªç­æ’åå·®å€¼æœ€å¤§çš„å­¦ç”Ÿã€‚
    è¿”å›çš„è¡¨æ ¼å½¢å¼ä¸ºï¼šç¬¬ä¸€åˆ—æ˜¯ç­çº§ï¼Œç¬¬äºŒåˆ—æ˜¯å§“åï¼Œç¬¬ä¸‰åˆ—æ˜¯è¿›æ­¥åæ¬¡ã€‚æ¯ä¸ªç­åº”è¯¥åªè¿”å›ä¸€ä¸ªå§“åå’Œæ’å"}
    

è¯·å°†æ‰€æœ‰è¾“å‡ºä½œä¸ºJSONå­—ç¬¦ä¸²è¿”å›ã€‚è¯·æ³¨æ„è¦å°†"columns"åˆ—è¡¨å’Œæ•°æ®åˆ—è¡¨ä¸­çš„æ‰€æœ‰å­—ç¬¦ä¸²éƒ½ç”¨åŒå¼•å·åŒ…å›´ã€‚
ä¾‹å¦‚ï¼š{"columns": ["Products", "Orders"], "data": [["32085Lip", 245], ["76439Eye", 178]]}

ä½ è¦å¤„ç†çš„ç”¨æˆ·è¯·æ±‚å¦‚ä¸‹ï¼š 
"""


def dataframe_agent(df, openai_api_key, query): 
    model = ChatOpenAI(model="qwen-long",
                       openai_api_key = openai_api_key, 
                       openai_api_base= "https://dashscope.aliyuncs.com/compatible-mode/v1",
                       temperature=0) # no creativity
    agent = create_pandas_dataframe_agent(llm=model,  # agentæ‰§è¡Œå™¨
                                          df=df,
                                          agent_executor_kwargs={"handle_parsing_errors": True}, 
                                          verbose=True) 
    prompt = PROMPT_TEMPLATE + query
    response = agent.invoke({"input": prompt})
    response_dict = json.loads(response["output"])
    return response_dict


import streamlit as st
from langchain.memory import ConversationBufferMemory
from pygwalker.api.streamlit import StreamlitRenderer
import pandas as pd


def create_chart(input_data, chart_type):
    df_data = pd.DataFrame(input_data["data"], columns=input_data["columns"])
    df_data.set_index(input_data["columns"][0], inplace=True)
    if chart_type == "bar":
        st.bar_chart(df_data)
    elif chart_type == "line":
        st.line_chart(df_data)
    elif chart_type == "scatter":
        st.scatter_chart(df_data)

def progress_max(df):
    df['è¿›æ­¥'] = df[df['è€ƒè¯•'] == 'ç¬¬2æ¬¡']['æ’å'] - df[df['è€ƒè¯•'] == 'ç¬¬1æ¬¡']['æ’å']
    progress_max = df[df['è€ƒè¯•'] == 'ç¬¬2æ¬¡'].sort_values('è¿›æ­¥', ascending=False).groupby('ç­çº§').head(1)[['å§“å', 'ç­çº§', 'è¿›æ­¥']].reset_index(drop=True)
    return progress_max


st.set_page_config(page_title="æˆç»©æ™ºèƒ½é—®ç­”ç¨‹åº", layout="wide")

# Add title to the Streamlit page
st.title("ğŸ§  æˆç»©æ™ºèƒ½é—®ç­”ç¨‹åº ğŸ’¡") 

with st.sidebar:
    openai_api_key = st.text_input("è¯·è¾“å…¥å¯†é’¥ï¼š", type="password")

# Function to cache the uploaded CSV file

def df(uploaded_file):
    if uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        return df
    return None


# Upload CSV file before selecting tool
uploaded_file = st.file_uploader("ä¸Šä¼ CSVæ ¼å¼çš„æ–‡ä»¶ï¼Œè®©AIå¸®ä½ æ¥åˆ†æå§", type="csv")
select_tool = None

if uploaded_file is not None:
    select_tool = st.selectbox("Select Tool", ["ä¸€é”®æ€»ç»“æˆç»©",
                                               "æ‰‹åŠ¨æˆç»©å¯è§†åŒ–", 
                                               "AIæˆç»©åˆ†æ"])

if select_tool == "æ‰‹åŠ¨æˆç»©å¯è§†åŒ–":
    st.title("ğŸ“ˆ æ‰‹åŠ¨æˆç»©å¯è§†åŒ–")
    if uploaded_file is not None:
        df = df(uploaded_file)
        if df is not None:
            renderer = StreamlitRenderer(df, spec="./gw_config.json", spec_io_mode="rw")
            renderer.explorer()
        else:
            st.write("Failed to load CSV file. Please make sure it is correctly formatted.")
    else:
        st.write("Please upload a CSV file.")

elif select_tool == "AIæˆç»©åˆ†æ":
    st.title("ğŸ” AIæˆç»©åˆ†æ")
    data = uploaded_file
    if data:
        st.session_state["df"] = pd.read_csv(data)
        with st.expander("åŸå§‹æ•°æ®"):
            st.dataframe(st.session_state["df"])


    query = st.text_area("è¯·è¾“å…¥ä½ å…³äºä»¥ä¸Šè¡¨æ ¼çš„é—®é¢˜ï¼Œæˆ–æ•°æ®æå–è¯·æ±‚ï¼Œæˆ–ç®€å•çš„å¯è§†åŒ–è¦æ±‚ï¼ˆæ”¯æŒæ•£ç‚¹å›¾ã€æŠ˜çº¿å›¾ã€æ¡å½¢å›¾ï¼‰ï¼š")
    button = st.button("ç”Ÿæˆå›ç­”")

    if button and not openai_api_key:
            st.info("è¯·è¾“å…¥ä½ çš„OpenAI APIå¯†é’¥")
    #    if button and not openai_api_base:
    #        st.info("è¯·è¾“å…¥ä½ çš„OpenAI Base URL")
    # if button and "df" not in st.session_state:
    #    st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
    if button and "df" in st.session_state:
        with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
            response_dict = dataframe_agent(st.session_state["df"], openai_api_key, query)  # ä¸º dataframe_agent() å‡½æ•°ä¼ é€’ df å’Œ query å‚æ•°
            if "answer" in response_dict:
                st.write(response_dict["answer"])
            if "table" in response_dict:
                st.table(pd.DataFrame(response_dict["table"]["data"],
                                      columns=response_dict["table"]["columns"]))
            if "bar" in response_dict:
                create_chart(response_dict["bar"], "bar")
            if "line" in response_dict:
                create_chart(response_dict["line"], "line")
            if "scatter" in response_dict:
                create_chart(response_dict["scatter"], "scatter")
            if "progress_max" in response_dict:
                st.write(response_dict["progress_max"])

elif select_tool == "ä¸€é”®æ€»ç»“æˆç»©":

    st.title("ğŸ¯ ä¸€é”®æ€»ç»“æˆç»©")
    button_summarize = st.button("ä¸€é”®æ€»ç»“")
    if button_summarize and uploaded_file is not None:
        df = pd.read_csv(uploaded_file)
        if df is not None:
            exam_counts = df['è€ƒè¯•'].nunique()
            for i in range(1, exam_counts+1):
                exam_data = df[df['è€ƒè¯•'] == f'ç¬¬{i}æ¬¡']
                exam_summary = exam_data.groupby('ç­çº§')['æ€»åˆ†'].agg(['mean', 'std']).reset_index()
                st.write(f"ç¬¬{i}æ¬¡è€ƒè¯•çš„æ¯ä¸ªç­çº§æ€»åˆ†å¹³å‡å€¼å’Œæ ‡å‡†å·®:")
                st.table(exam_summary)
            st.write("å¦‚æœæœ‰è¿›ä¸€æ­¥çš„éœ€æ±‚ï¼Œæ¬¢è¿é€‰æ‹©â€œAIæ•°æ®åˆ†æâ€ã€‚")
        else:
            st.write("åŠ è½½CSVæ–‡ä»¶å¤±è´¥ï¼Œè¯·ç¡®ä¿æ ¼å¼æ­£ç¡®ã€‚")
    #else:
        #st.write("è¯·ä¸Šä¼ ä¸€ä¸ªCSVæ–‡ä»¶ä»¥è¿›è¡Œæ•°æ®æ€»ç»“ã€‚")
    st.write("---")
    st.write("Created by ğŸ¯")